{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Gaussian Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from lightgbmlss.model import LightGBMLSS\n",
    "from lightgbmlss.utils import create_mv_dataset\n",
    "from lightgbmlss.distributions.Gaussian import MultivariateGaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We generate data with a single input and three outputs. The input and outputs have a smooth, non-monotonic relationship and correlated noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "x = np.linspace(0, 10, n_samples)\n",
    "\n",
    "# Create correlated noise with increasing magnitude\n",
    "def scale_cov_matrix(x, base_cov, scale_factor=0.1):\n",
    "    return base_cov * (1 + scale_factor * x)\n",
    "\n",
    "\n",
    "cov_matrix = np.array([[0.25, 0.15, 0.1], [0.15, 0.49, 0.2], [0.1, 0.2, 0.36]])\n",
    "\n",
    "correlated_noise = np.array(\n",
    "    [\n",
    "        np.random.multivariate_normal(\n",
    "            mean=[0, 0, 0], cov=scale_cov_matrix(xi, cov_matrix)\n",
    "        )\n",
    "        for xi in x\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Generate three dependent variables with smooth, non-monotonic relationships and correlated noise\n",
    "y1_ = 2 * np.sin(x) + 0.5 * x\n",
    "y1 = y1_ + correlated_noise[:, 0]\n",
    "y2_ = 3 * np.cos(0.5 * x) + 0.3 * x**2\n",
    "y2 = y2_ + correlated_noise[:, 1]\n",
    "y3_ = 1.5 * np.sin(0.7 * x) * np.cos(0.3 * x) + 0.2 * x\n",
    "y3 = y3_ + correlated_noise[:, 2]\n",
    "\n",
    "# Combine the data\n",
    "data = np.column_stack((x, y1, y2, y3))\n",
    "real_data = np.column_stack((x, y1_, y2_, y3_))\n",
    "\n",
    "# Plot the relationships\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "fig.suptitle(\"Relationships between input and outputs (with correlated noise)\")\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.scatter(x, data[:, i + 1], alpha=0.5)\n",
    "    ax.set_xlabel(\"Input\")\n",
    "    ax.set_ylabel(f\"Output {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"First few rows of the data:\")\n",
    "print(data[:5])\n",
    "\n",
    "# Plot correlation matrix of the outputs\n",
    "correlation_matrix = np.corrcoef(data[:, 1:].T)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(correlation_matrix, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation Matrix of Outputs\")\n",
    "plt.xticks(range(3), [\"y1\", \"y2\", \"y3\"])\n",
    "plt.yticks(range(3), [\"y1\", \"y2\", \"y3\"])\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j, i, f\"{correlation_matrix[i, j]:.2f}\", ha=\"center\", va=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating special multivariate LightGBM dataset\n",
    "\n",
    "Since LightGBM only supports a single target column, we need to create a special dataset for multivariate data.\n",
    "\n",
    "We do this by stacking the target columns on top of each other, and repeating the feature columns for each target column. This logic is contained in the `create_mv_dataset` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lightgbm dataset\n",
    "dtrain = create_mv_dataset(\n",
    "    data[:, 0].reshape(-1, 1),\n",
    "    data[:, 1:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Selection\n",
    "\n",
    "We specify a Multivariate Gaussian distribution. By modifying the speciﬁcation in the following, the user can specify alternative distributional assumptions. This includes the option to choose from a wide range of parametric univariate distributions, as well as to model the data using Normalizing Flows. The user also has different function arguments for each distribution:\n",
    "\n",
    "- `stabilization`: specifies the stabilization method for the Gradient and Hessian. Options are `None`, `MAD` and `L2`.\n",
    "- `response_fn`: specifies $h_{k}(\\cdot)$ and transforms the distributional parameter to the correct support. Here, we specify an exponential for $\\sigma_{i}(\\cdot)$ only.\n",
    "- `loss_fn`: specifies the loss function used for training.  Options are `nll` (negative log-likelihood) or `crps` (continuous ranked probability score).\n",
    "\n",
    "For additional details, see `?MultivariateGaussian`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgblss = LightGBMLSS(\n",
    "    MultivariateGaussian(stabilization=\"None\", response_fn=\"exp\", loss_fn=\"nll\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "Hyperparameter tuning and optimization is essential when fitting a model to all parameters of a Multivariate Gaussian at once. It's much more common for instabilities to arise with many interrelated outputs, meaning the default parameters are often not suitable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"eta\":                      [\"float\", {\"low\": 1e-5,   \"high\": 1,     \"log\": True}],\n",
    "    \"lambda_l1\":                [\"float\", {\"low\": 1e-5, \"high\": 100.0, \"log\": True}],\n",
    "    \"lambda_l2\":                [\"float\", {\"low\": 1e-5, \"high\": 100.0, \"log\": True}],\n",
    "    \"min_child_samples\":        [\"int\", {\"low\": 5, \"high\": 100, \"log\": False}],  # set to constant for this example\n",
    "    \"boosting\":                 [\"categorical\", [\"gbdt\"]],\n",
    "}\n",
    "\n",
    "np.random.seed(123)\n",
    "opt_param = lgblss.hyper_opt(param_dict,\n",
    "                             dtrain,\n",
    "                             num_boost_round=100,        # Number of boosting iterations.\n",
    "                             nfold=3,                    # Number of cv-folds.\n",
    "                             early_stopping_rounds=20,   # Number of early-stopping rounds\n",
    "                             max_minutes=60,             # Time budget in minutes, i.e., stop study after the given number of minutes.\n",
    "                             n_trials=30,               # The number of trials. If this argument is set to None, there is no limitation on the number of trials.\n",
    "                             silence=True,               # Controls the verbosity of the trail, i.e., user can silence the outputs of the trail.\n",
    "                             seed=123,                   # Seed used to generate cv-folds.\n",
    "                             hp_seed=123                 # Seed for random number generator used in the Bayesian hyperparameter search.\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting results from all trials\n",
    "lgblss.study.trials_dataframe().sort_values(\"value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "We use the optimized hyper-parameters and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "opt_params = opt_param.copy()\n",
    "n_rounds = opt_params[\"opt_rounds\"]\n",
    "del opt_params[\"opt_rounds\"]\n",
    "\n",
    "# Train Model with optimized hyperparameters\n",
    "lgblss.train(opt_params,\n",
    "             dtrain,\n",
    "             num_boost_round=n_rounds\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Similar to a LightGBM model, we now predict from the trained model. Different options are available:\n",
    "\n",
    "- `samples`: draws `n_samples` from the predicted distribution.\n",
    "- `quantiles`: calculates quantiles from the predicted distribution.\n",
    "- `parameters`: returns predicted distributional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Number of samples to draw from predicted distribution\n",
    "n_samples = 1000\n",
    "quant_sel = [0.05, 0.95] # Quantiles to calculate from predicted distribution\n",
    "\n",
    "# Make predictions\n",
    "preds = lgblss.predict(data[:, [0]])\n",
    "\n",
    "# Sample from predicted distribution\n",
    "pred_samples = lgblss.predict(data[:, [0]],\n",
    "                              pred_type=\"samples\",\n",
    "                              n_samples=n_samples,\n",
    "                              seed=123)\n",
    "\n",
    "# Calculate quantiles from predicted distribution\n",
    "pred_quantiles = lgblss.predict(data[:, [0]],\n",
    "                                pred_type=\"quantiles\",\n",
    "                                n_samples=n_samples,\n",
    "                                quantiles=quant_sel)\n",
    "\n",
    "# Return predicted distributional parameters\n",
    "pred_params = lgblss.predict(data[:, [0]],\n",
    "                             pred_type=\"parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "fig.suptitle(\"LightGBMLSS MV Gaussian Predictions\", fontsize=16)\n",
    "\n",
    "# Compute covariance matrices\n",
    "st = preds.iloc[:, 3:].to_numpy().reshape(-1, 3, 3, order=\"C\")\n",
    "cov = np.zeros_like(st)\n",
    "for i in range(st.shape[0]):\n",
    "    cov[i] = st[i] @ st[i].T\n",
    "\n",
    "for i in range(3):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    mean = preds[f\"loc_{i}\"]\n",
    "    std = np.sqrt(cov[:, i, i])\n",
    "    lower = mean - 1.96 * std\n",
    "    upper = mean + 1.96 * std\n",
    "    \n",
    "    ax.plot(data[:, [0]], mean, label=\"Mean\")\n",
    "    ax.fill_between(data[:, 0], lower, upper, alpha=0.3, label=\"95% CI\")\n",
    "    ax.scatter(data[:, 0], data[:, i+1], alpha=0.5, label=\"Data\")\n",
    "    ax.set_ylabel(f\"Y{i+1}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "axes[-1].set_xlabel(\"Input\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_sample0</th>\n",
       "      <th>y_sample1</th>\n",
       "      <th>y_sample2</th>\n",
       "      <th>y_sample3</th>\n",
       "      <th>y_sample4</th>\n",
       "      <th>y_sample5</th>\n",
       "      <th>y_sample6</th>\n",
       "      <th>y_sample7</th>\n",
       "      <th>y_sample8</th>\n",
       "      <th>y_sample9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_sample990</th>\n",
       "      <th>y_sample991</th>\n",
       "      <th>y_sample992</th>\n",
       "      <th>y_sample993</th>\n",
       "      <th>y_sample994</th>\n",
       "      <th>y_sample995</th>\n",
       "      <th>y_sample996</th>\n",
       "      <th>y_sample997</th>\n",
       "      <th>y_sample998</th>\n",
       "      <th>y_sample999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.969691</td>\n",
       "      <td>8.598016</td>\n",
       "      <td>11.316233</td>\n",
       "      <td>11.196012</td>\n",
       "      <td>-0.772420</td>\n",
       "      <td>10.135987</td>\n",
       "      <td>14.128653</td>\n",
       "      <td>7.630763</td>\n",
       "      <td>12.698465</td>\n",
       "      <td>8.239548</td>\n",
       "      <td>...</td>\n",
       "      <td>10.933374</td>\n",
       "      <td>11.149927</td>\n",
       "      <td>8.531628</td>\n",
       "      <td>9.486668</td>\n",
       "      <td>10.501742</td>\n",
       "      <td>9.149441</td>\n",
       "      <td>11.645898</td>\n",
       "      <td>7.640362</td>\n",
       "      <td>9.958486</td>\n",
       "      <td>6.289453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.461757</td>\n",
       "      <td>9.600316</td>\n",
       "      <td>10.147589</td>\n",
       "      <td>12.562353</td>\n",
       "      <td>16.377707</td>\n",
       "      <td>10.912953</td>\n",
       "      <td>9.325396</td>\n",
       "      <td>9.916863</td>\n",
       "      <td>7.682811</td>\n",
       "      <td>17.506680</td>\n",
       "      <td>...</td>\n",
       "      <td>10.509146</td>\n",
       "      <td>7.077166</td>\n",
       "      <td>2.610499</td>\n",
       "      <td>8.764830</td>\n",
       "      <td>16.280003</td>\n",
       "      <td>8.840451</td>\n",
       "      <td>8.440387</td>\n",
       "      <td>16.157856</td>\n",
       "      <td>9.217056</td>\n",
       "      <td>8.147191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.655623</td>\n",
       "      <td>10.095434</td>\n",
       "      <td>10.497488</td>\n",
       "      <td>8.415718</td>\n",
       "      <td>10.877867</td>\n",
       "      <td>8.264465</td>\n",
       "      <td>10.300594</td>\n",
       "      <td>11.423710</td>\n",
       "      <td>10.838738</td>\n",
       "      <td>9.795403</td>\n",
       "      <td>...</td>\n",
       "      <td>11.465590</td>\n",
       "      <td>10.625634</td>\n",
       "      <td>8.727895</td>\n",
       "      <td>9.756786</td>\n",
       "      <td>8.575561</td>\n",
       "      <td>9.242844</td>\n",
       "      <td>9.997345</td>\n",
       "      <td>10.150554</td>\n",
       "      <td>10.739549</td>\n",
       "      <td>9.458581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.315505</td>\n",
       "      <td>15.109694</td>\n",
       "      <td>9.312259</td>\n",
       "      <td>-3.643276</td>\n",
       "      <td>12.262859</td>\n",
       "      <td>8.238321</td>\n",
       "      <td>7.009054</td>\n",
       "      <td>6.200121</td>\n",
       "      <td>3.878844</td>\n",
       "      <td>13.135740</td>\n",
       "      <td>...</td>\n",
       "      <td>19.848660</td>\n",
       "      <td>15.314698</td>\n",
       "      <td>8.589100</td>\n",
       "      <td>12.168641</td>\n",
       "      <td>8.016486</td>\n",
       "      <td>13.352606</td>\n",
       "      <td>9.907011</td>\n",
       "      <td>8.088248</td>\n",
       "      <td>12.577316</td>\n",
       "      <td>7.965759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.067125</td>\n",
       "      <td>10.200111</td>\n",
       "      <td>9.035689</td>\n",
       "      <td>8.689579</td>\n",
       "      <td>10.475836</td>\n",
       "      <td>8.348648</td>\n",
       "      <td>6.953860</td>\n",
       "      <td>7.018825</td>\n",
       "      <td>11.546731</td>\n",
       "      <td>4.925195</td>\n",
       "      <td>...</td>\n",
       "      <td>9.588341</td>\n",
       "      <td>12.277424</td>\n",
       "      <td>9.194149</td>\n",
       "      <td>13.164710</td>\n",
       "      <td>11.918127</td>\n",
       "      <td>7.771739</td>\n",
       "      <td>10.544153</td>\n",
       "      <td>9.177776</td>\n",
       "      <td>7.839355</td>\n",
       "      <td>11.506623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_sample0  y_sample1  y_sample2  y_sample3  y_sample4  y_sample5  \\\n",
       "0  10.969691   8.598016  11.316233  11.196012  -0.772420  10.135987   \n",
       "1   9.461757   9.600316  10.147589  12.562353  16.377707  10.912953   \n",
       "2   9.655623  10.095434  10.497488   8.415718  10.877867   8.264465   \n",
       "3   7.315505  15.109694   9.312259  -3.643276  12.262859   8.238321   \n",
       "4  11.067125  10.200111   9.035689   8.689579  10.475836   8.348648   \n",
       "\n",
       "   y_sample6  y_sample7  y_sample8  y_sample9  ...  y_sample990  y_sample991  \\\n",
       "0  14.128653   7.630763  12.698465   8.239548  ...    10.933374    11.149927   \n",
       "1   9.325396   9.916863   7.682811  17.506680  ...    10.509146     7.077166   \n",
       "2  10.300594  11.423710  10.838738   9.795403  ...    11.465590    10.625634   \n",
       "3   7.009054   6.200121   3.878844  13.135740  ...    19.848660    15.314698   \n",
       "4   6.953860   7.018825  11.546731   4.925195  ...     9.588341    12.277424   \n",
       "\n",
       "   y_sample992  y_sample993  y_sample994  y_sample995  y_sample996  \\\n",
       "0     8.531628     9.486668    10.501742     9.149441    11.645898   \n",
       "1     2.610499     8.764830    16.280003     8.840451     8.440387   \n",
       "2     8.727895     9.756786     8.575561     9.242844     9.997345   \n",
       "3     8.589100    12.168641     8.016486    13.352606     9.907011   \n",
       "4     9.194149    13.164710    11.918127     7.771739    10.544153   \n",
       "\n",
       "   y_sample997  y_sample998  y_sample999  \n",
       "0     7.640362     9.958486     6.289453  \n",
       "1    16.157856     9.217056     8.147191  \n",
       "2    10.150554    10.739549     9.458581  \n",
       "3     8.088248    12.577316     7.965759  \n",
       "4     9.177776     7.839355    11.506623  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quant_0.05</th>\n",
       "      <th>quant_0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.405031</td>\n",
       "      <td>14.896293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.210804</td>\n",
       "      <td>15.007315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.298658</td>\n",
       "      <td>11.832828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.962531</td>\n",
       "      <td>17.087187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.807709</td>\n",
       "      <td>14.909888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quant_0.05  quant_0.95\n",
       "0    5.405031   14.896293\n",
       "1    5.210804   15.007315\n",
       "2    8.298658   11.832828\n",
       "3    2.962531   17.087187\n",
       "4    4.807709   14.909888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_quantiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.984035</td>\n",
       "      <td>2.921586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.979074</td>\n",
       "      <td>2.909918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.979074</td>\n",
       "      <td>1.065636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.979074</td>\n",
       "      <td>4.529788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.979074</td>\n",
       "      <td>3.121158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loc     scale\n",
       "0  9.984035  2.921586\n",
       "1  9.979074  2.909918\n",
       "2  9.979074  1.065636\n",
       "3  9.979074  4.529788\n",
       "4  9.979074  3.121158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_params.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
